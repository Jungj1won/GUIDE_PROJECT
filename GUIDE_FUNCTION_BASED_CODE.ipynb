{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import"
      ],
      "metadata": {
        "id": "aaSb1Xt6hjCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjxwL3fRhQEW",
        "outputId": "a56e168c-2768-423c-bdda-eeaf9446df5d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-09-01T03:37:20.972372Z",
          "iopub.status.busy": "2023-09-01T03:37:20.972023Z",
          "iopub.status.idle": "2023-09-01T03:37:35.437970Z",
          "shell.execute_reply": "2023-09-01T03:37:35.437252Z",
          "shell.execute_reply.started": "2023-09-01T03:37:20.972345Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SLvWBrWGRdT",
        "outputId": "d695ba05-39e4-4faa-c7f6-520ae1450592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.9/21.9 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.8/128.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optuna\n",
            "  Downloading optuna-3.5.0-py3-none-any.whl (413 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.4/413.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.27)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.10.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.2 alembic-1.13.1 colorlog-6.8.2 optuna-3.5.0\n",
            "Linux version: 6.1.58+\n",
            "Python version: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "xgboost version: 2.0.3\n",
            "pandas version: 1.5.3\n",
            "numpy version: 1.25.2\n",
            "optuna version: 3.5.0\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!pip install -q sktime\n",
        "!pip install optuna\n",
        "from tqdm import tqdm\n",
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import math\n",
        "import os\n",
        "from xgboost import XGBRegressor\n",
        "import platform\n",
        "import optuna\n",
        "from sktime.forecasting.model_selection import temporal_train_test_split\n",
        "\n",
        "if platform.system() == \"Linux\":\n",
        "    linux_version = platform.uname().release\n",
        "    print(\"Linux version:\", linux_version)\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Python version:\", sys.version)\n",
        "print(\"xgboost version:\", xgb.__version__)\n",
        "print(\"pandas version:\", pd.__version__)\n",
        "print(\"numpy version:\", np.__version__)\n",
        "print(\"optuna version:\", optuna.__version__)\n",
        "\n",
        "base_path = '/content/drive/MyDrive/4-1/DScover7기/가이드프로젝트/dataset/' # 본인의 datapath를 입력\n",
        "\n",
        "def SMAPE(true, pred): # Symmetric Mean Absolute Percentage Error(SMAPE)를 계산하는 함수\n",
        "\n",
        "   # SMAPE는 실제 값과 예측 값 사이의 차이를 백분율로 나타내는 정확도의 지표\n",
        "   # 이 메트릭은 0과 200 사이의 값을 가지며, 값이 낮을수록 예측의 정확도가 높다는 것을 의미한다.\n",
        "\n",
        "   # true: 실제 값이 담긴 numpy 배열\n",
        "   # pred: 예측 값이 담긴 numpy 배열\n",
        "\n",
        "    return np.mean((np.abs(true - pred)) / (np.abs(true) + np.abs(pred))) * 200\n",
        "\n",
        "def weighted_mse(alpha=1): # MSE 계산 함수\n",
        "\n",
        "   # 이 함수는 예측 오차에 가중치를 적용하여 더 큰 오차에 대해 더 큰 패널티를 부과하거나, 반대로 더 작은 오차에 대해 더 작은 패널티를 부과할 수 있다.\n",
        "   # alpha 매개변수를 통해 오차에 대한 가중치를 조정할 수 있습니다.\n",
        "\n",
        "   # alpha: 실제 값과 예측 값 사이의 오차가 양수일 때 적용되는 가중치. 기본값은 1\n",
        "\n",
        "   # 반환 값:\n",
        "   # weighted_mse_fixed 함수: 이 함수는 실제 레이블과 예측된 값을 매개변수로 받아 Gradient와 2차 미분 값(hess)을 반환한다.\n",
        "\n",
        "    def weighted_mse_fixed(label, pred):\n",
        "        residual = (label - pred).astype(\"float\")\n",
        "        # 오차가 양수인 경우와 그렇지 않은 경우에 대해 다른 Gradient를 계산\n",
        "        grad = np.where(residual > 0, -2 * alpha * residual, -2 * residual)\n",
        "        # 오차가 양수인 경우와 그렇지 않은 경우에 대해 다른 hess을 계산\n",
        "        hess = np.where(residual > 0, 2 * alpha, 2.0)\n",
        "        return grad, hess\n",
        "\n",
        "    return weighted_mse_fixed"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#함수 선언"
      ],
      "metadata": {
        "id": "OyTmM-WBhqUC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-01T03:37:35.440007Z",
          "iopub.status.busy": "2023-09-01T03:37:35.439642Z",
          "iopub.status.idle": "2023-09-01T03:37:35.489578Z",
          "shell.execute_reply": "2023-09-01T03:37:35.488516Z",
          "shell.execute_reply.started": "2023-09-01T03:37:35.439985Z"
        },
        "trusted": true,
        "id": "3CcuOea0GRdU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from datetime import datetime\n",
        "import math\n",
        "\n",
        "def add_data(df):# 데이터프레임에 대해 각 관측치에 대해 무작위의 변화를 주어 데이터를 증식\n",
        "    for i in range(2): # 아래의 과정을 2번 반복\n",
        "        np.random.seed(i)\n",
        "        num_rows = len(df) # 주어진 데이터프레임(df)의 각 행에 대해\n",
        "        random_factors = ['temp', 'prec', 'wind', 'hum'] # 주어진 환경 요인('temp', 'prec', 'wind', 'hum')에 대해\n",
        "\n",
        "        random_data = {\n",
        "            factor: np.round(df[factor] * np.random.uniform(0.9, 1.1, num_rows), 1) # 0.9에서 1.1 사이의 난수를 곱하여 새로운 데이터를 생성\n",
        "            for factor in random_factors\n",
        "        }\n",
        "\n",
        "        new_df = df.copy()\n",
        "        new_df.update(pd.DataFrame(random_data))\n",
        "        df = pd.concat([df, new_df], ignore_index=True) # 이를 원본 데이터프레임에 추가\n",
        "\n",
        "    df = df.sort_values(by=['building', 'date_time']).reset_index(drop=True) # 최종적으로 'building'과 'date_time'을 기준으로 정렬된 데이터프레임을 반환\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def weather(train): # 'prec'(강수량) 특성을 기반으로 'weather' 특성을 생성\n",
        "    condition = train['prec'] > 0\n",
        "    filtered_df = train[condition].index.tolist()\n",
        "    train['weather'] = 0\n",
        "\n",
        "    for idx in filtered_df:\n",
        "        for offset in range(-3, 4): # 강수량이 0보다 큰 관측치 주변 (+/- 3시간)\n",
        "            new_idx = idx + offset\n",
        "            if 0 <= new_idx < len(train):\n",
        "                train.loc[new_idx, 'weather'] = 1 # 'weather' 특성을 1로 설정하여 비가 온 것으로 표시\n",
        "\n",
        "    return train"
      ],
      "metadata": {
        "id": "bdvEwZPQnAuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def time_features(data, mode): # 날짜와 시간에서 파생된 여러 시간 관련 특성들을 생성\n",
        "    date = pd.to_datetime(data['date_time'])\n",
        "    # 시간, 요일, 월, 주, 일\n",
        "    data['hour'] = date.dt.hour\n",
        "    data['dow'] = date.dt.weekday\n",
        "    data['month'] = date.dt.month\n",
        "    data['week'] = date.dt.isocalendar().week.astype(np.int32)\n",
        "    data['day'] = date.dt.day\n",
        "\n",
        "    # 시간의 사인 및 코사인 변환(시간의 주기성을 반영하기 위한 작업임)\n",
        "    data['sin_time'] = np.sin(2 * np.pi * data['hour'] / 24)\n",
        "    data['cos_time'] = np.cos(2 * np.pi * data['hour'] / 24)\n",
        "\n",
        "    # 특정 건물과 날짜에 대한 공휴일 특성을 설정\n",
        "    data['holiday'] = data['dow'].apply(lambda x: 0 if x < 5 else 1)\n",
        "    data['date'] = date.dt.date\n",
        "\n",
        "    building_dates = [['2022-06-07', '2022-06-17'], ['2022-07-31', '2022-07-23', '2022-07-20'], ['2022-08-16', '2022-08-17']]\n",
        "\n",
        "    for index, b in enumerate([2, 3 ,54]):\n",
        "        data.loc[data['building'] == b, 'holiday'] = 0\n",
        "        data.loc[(data['building'] == b) & (data['dow'] == 0) , 'holiday'] = 1\n",
        "        data.loc[(data['building'] == b) & (data['date'].isin([pd.to_datetime(i).date() for i in building_dates[index]])), 'holiday'] = 1\n",
        "\n",
        "    data.loc[(data['building'] != 14) & (data['date'].isin([pd.to_datetime(i).date() for i in ['2022-06-01', '2022-06-06', '2022-08-15']])), 'holiday'] = 1\n",
        "    data.loc[(data['building'] == 14) & (data['date'].isin([pd.to_datetime(i).date() for i in ['2022-06-14']])) , 'holiday'] = 1\n",
        "    data.loc[data['building'] == 85, 'holiday'] = 0\n",
        "\n",
        "    def week_of_month(date): # 입력날짜가 해당월의 짝수 주의 일요일인지를 판별(마트 휴일)\n",
        "        first_day = date.replace(day=1)\n",
        "        if (date.isocalendar().week - first_day.isocalendar().week + 1) % 2 == 0:\n",
        "            if date.weekday() == 6:\n",
        "                return 1\n",
        "        return 0\n",
        "\n",
        "    data['week_of_month'] = data['date'].apply(week_of_month)\n",
        "\n",
        "    target_buildings = [87,88,89,90,91,92] # 마트 건물 번호\n",
        "    data.loc[(data['building'].isin(target_buildings)) , 'holiday'] = 0\n",
        "    data.loc[(data['building'].isin(target_buildings)) & (data['week_of_month'] == 1), 'holiday'] = 1\n",
        "\n",
        "    building_dates = [['2022-06-20', '2022-07-11', '2022-08-08', '2022-06-17'], ['2022-06-13', '2022-07-25', '2022-08-01'],\n",
        "                     ['2022-07-18', '2022-08-08'], ['2022-06-20', '2022-07-18', '2022-06-17', '2022-08-08'],\n",
        "                     ['2022-06-27', '2022-07-25', '2022-08-08'], ['2022-06-13', '2022-07-11', '2022-08-22'],\n",
        "                     ['2022-06-10', '2022-08-10', '2022-07-10', '2022-07-24', '2022-06-26', '2022-08-28']]\n",
        "\n",
        "    # 'mode' 매개변수에 따라 특정 처리가 다르게 적용\n",
        "    if mode == 'byb' or mode == 'gu_byb':\n",
        "        for index, b in enumerate([37,38,39,40,41,42,86]):\n",
        "            data.loc[data['building'] == b, 'holiday'] = 0\n",
        "            data.loc[(data['building'] == b) & (data['date'].isin([pd.to_datetime(i).date() for i in building_dates[index]])), 'holiday'] = 1\n",
        "\n",
        "    if mode == 'all' or mode == 'gu_all':\n",
        "        data.loc[data['building'] == 86, 'holiday'] = 0\n",
        "        data.loc[(data['building'] == 86) & (data['date'].isin([pd.to_datetime(i).date() for i in building_dates[-1]+['2022-07-30']])), 'holiday'] = 1\n",
        "\n",
        "    data['date'] = pd.to_datetime(data['date_time'], format='%Y-%m-%d')\n",
        "    return data"
      ],
      "metadata": {
        "id": "hVFPInyCnAry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def side_indicator(data):\n",
        "    data['THI'] = 9/5 * data['temp'] - 0.55 * (1 - data['hum']/100) * (9/5 * data['temp'] - 26) + 32 # 볼쾌지수(THI) 계산식\n",
        "    data['WC'] = 13.12 + 0.6215 * data['temp'] - 13.947 * np.power(data['wind'], 0.16) + 0.486 * data['temp'] * np.power(data['wind'], 0.16) # 체감온도(WC) 계산식\n",
        "\n",
        "    def calculate_cdh(xs): # 누적냉방도수(CDH) 계산식\n",
        "        ys = []\n",
        "        for i in range(len(xs)):\n",
        "            if i < 11:\n",
        "                ys.append(np.sum(xs[:(i+1)] - 26))\n",
        "            else:\n",
        "                ys.append(np.sum(xs[(i-11):(i+1)] - 26))\n",
        "        return np.array(ys)\n",
        "\n",
        "    cdhs = []\n",
        "    for num in range(1, 101):\n",
        "        temp = data[data['building'] == num]\n",
        "        cdh = calculate_cdh(temp['temp'].values)\n",
        "        cdhs.extend(cdh)\n",
        "    data['CDH'] = cdhs\n",
        "\n",
        "    return data\n",
        "\n",
        "def temp_features(data): # 평균, 최대, 최소 온도 및 온도 차이를 기반으로 여러 온도 관련 특성을 계산\n",
        "    # 평균, 최대, 최소 온도 계산 및 데이터프레임에 병합\n",
        "\n",
        "    # 평균\n",
        "    avg_temp = pd.pivot_table(data[data['hour']%3 == 0], values = 'temp', index = ['building', 'day', 'month'], aggfunc = np.mean).reset_index()\n",
        "    avg_temp.rename(columns={'temp': 'avg_temp'}, inplace=True)\n",
        "    data = pd.merge(data, avg_temp, on=['building', 'day', 'month'], how='left')\n",
        "\n",
        "    # 최대\n",
        "    max_temp = pd.pivot_table(data, values = 'temp', index = ['building', 'day', 'month'], aggfunc = np.max).reset_index()\n",
        "    max_temp.rename(columns={'temp': 'max_temp'}, inplace=True)\n",
        "    data = pd.merge(data, max_temp, on=['building', 'day', 'month'], how='left')\n",
        "\n",
        "    # 최소\n",
        "    min_temp = pd.pivot_table(data, values = 'temp', index = ['building', 'day', 'month'], aggfunc = np.min).reset_index()\n",
        "    min_temp.rename(columns={'temp': 'min_temp'}, inplace=True)\n",
        "    data = pd.merge(data, min_temp, on=['building', 'day', 'month'], how='left')\n",
        "\n",
        "    data['temp_diff'] = data['max_temp'] - data['min_temp']\n",
        "\n",
        "    return data\n",
        "\n",
        "def process_data(data, mode): # 데이터 전처리의 주 함수로, 다른 함수들을 호출하여 데이터에 여러 특성을 추가하고 누락된 값들을 처리\n",
        "    # 데이터 전처리 단계 호출\n",
        "    data['wind'] = data['wind'].fillna(method='ffill')\n",
        "    data['hum'] = data['hum'].fillna(method='ffill')\n",
        "    data = data.fillna(0)\n",
        "\n",
        "    data = time_features(data, mode)\n",
        "    data = side_indicator(data)\n",
        "    data = temp_features(data)\n",
        "\n",
        "    data['summer_cos'] = data['date'].apply(summer_cos)\n",
        "    data['summer_sin'] = data['date'].apply(summer_sin)\n",
        "\n",
        "    return data\n",
        "\n"
      ],
      "metadata": {
        "id": "nL60bVUBnApa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_std(train, test, mode):\n",
        "    ratio = np.array([0.985]+[0.98]*2+[0.995]*2+[0.99]*2)\n",
        "    if mode == 'byb':\n",
        "        train['target'] = train.apply(lambda row: row['target'] * ratio[row['dow']], axis=1)\n",
        "    elif mode == 'all':\n",
        "        ratio -= 0.005\n",
        "        train['target'] = train.apply(lambda row: row['target'] * ratio[row['dow']], axis=1)\n",
        "\n",
        "    # 평균 및 표준편차 계산 및 데이터프레임에 병합\n",
        "    power_mean = pd.pivot_table(train, values = 'target', index = ['building', 'hour', 'dow'], aggfunc = np.mean).reset_index()\n",
        "    power_mean.rename(columns={'target': 'dow_hour_mean'}, inplace=True)\n",
        "    train = pd.merge(train, power_mean, on=['building', 'hour', 'dow'], how='left')\n",
        "    test = pd.merge(test, power_mean, on=['building', 'hour', 'dow'], how='left')\n",
        "\n",
        "    power_holiday_mean = pd.pivot_table(train, values = 'target', index = ['building', 'hour', 'holiday'], aggfunc = np.mean).reset_index()\n",
        "    power_holiday_mean.rename(columns={'target': 'holiday_mean'}, inplace=True)\n",
        "    train = pd.merge(train, power_holiday_mean, on=['building', 'hour', 'holiday'], how='left')\n",
        "    test = pd.merge(test, power_holiday_mean, on=['building', 'hour', 'holiday'], how='left')\n",
        "\n",
        "    power_holiday_std = pd.pivot_table(train, values = 'target', index = ['building', 'hour', 'holiday'], aggfunc = np.std).reset_index()\n",
        "    power_holiday_std.rename(columns={'target': 'holiday_std'}, inplace=True)\n",
        "    train = pd.merge(train, power_holiday_std, on=['building', 'hour', 'holiday'], how='left')\n",
        "    test = pd.merge(test, power_holiday_std, on=['building', 'hour', 'holiday'], how='left')\n",
        "\n",
        "    power_hour_mean = pd.pivot_table(train, values = 'target', index = ['building', 'hour',], aggfunc = np.mean).reset_index()\n",
        "    power_hour_mean.rename(columns={'target': 'hour_mean'}, inplace=True)\n",
        "    train = pd.merge(train, power_hour_mean, on=['building', 'hour', ], how='left')\n",
        "    test = pd.merge(test, power_hour_mean, on=['building', 'hour', ], how='left')\n",
        "\n",
        "    power_hour_std = pd.pivot_table(train, values = 'target', index = ['building', 'hour',], aggfunc = np.std).reset_index()\n",
        "    power_hour_std.rename(columns={'target': 'hour_std'}, inplace=True)\n",
        "    train = pd.merge(train, power_hour_std, on=['building', 'hour', ], how='left')\n",
        "    test = pd.merge(test, power_hour_std, on=['building', 'hour', ], how='left')\n",
        "\n",
        "    if mode == 'all' or mode == 'gu_all':\n",
        "        train['date'] = pd.to_datetime(train['date_time'], format='%Y-%m-%d').dt.date\n",
        "        test['date'] = pd.to_datetime(test['date_time'], format='%Y-%m-%d').dt.date\n",
        "        building_dates = [['2022-06-20', '2022-07-11', '2022-08-08', '2022-06-17'], ['2022-06-13', '2022-07-25', '2022-08-01'],\n",
        "                         ['2022-07-18', '2022-08-08'], ['2022-06-20', '2022-07-18', '2022-06-17', '2022-08-08'],\n",
        "                         ['2022-06-27', '2022-07-25', '2022-08-08'], ['2022-06-13', '2022-07-11', '2022-08-22']]\n",
        "\n",
        "        for index, b in enumerate([37,38,39,40,41,42]):\n",
        "            train.loc[train['building'] == b, 'holiday'] = 0\n",
        "            train.loc[(train['building'] == b) & (train['date'].isin([pd.to_datetime(i).date() for i in building_dates[index]])), 'holiday'] = 1\n",
        "            test.loc[test['building'] == b, 'holiday'] = 0\n",
        "            test.loc[(test['building'] == b) & (test['date'].isin([pd.to_datetime(i).date() for i in building_dates[index]])), 'holiday'] = 1\n",
        "\n",
        "    return train, test"
      ],
      "metadata": {
        "id": "iddixCqwpHQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_info(data, is_train=True): # 건물 정보 데이터를 전처리하는 함수\n",
        "    # 건물 정보 데이터 전처리\n",
        "    data.columns = ['building', 'type', 'all_area', 'cool_area', 'sun']\n",
        "    data['sun'] = data['sun'].replace('-', 0).astype('float')\n",
        "\n",
        "    value_dict = {value: index for index, value in enumerate(data['type'].unique())}\n",
        "    data['type'] = data['type'].map(value_dict)\n",
        "\n",
        "    # 조건에 따라 'cool_area' 값을 조정\n",
        "    filtered_data = data[(data['type'] == 7) & (data['cool_area'] != 0)]\n",
        "    result = (filtered_data['all_area'].iloc[1:].sum() / filtered_data['cool_area'].iloc[1:].sum())\n",
        "    condition = (data['type'] == 7) & (data['cool_area'] == 0)\n",
        "    data.loc[condition, 'cool_area'] = (data.loc[condition, 'all_area'] / result).astype('int')\n",
        "\n",
        "    filtered_data = data[(data['type'] == 9) & (data['cool_area'] > 500)]\n",
        "    result = (filtered_data['all_area'].sum() / filtered_data['cool_area'].sum())\n",
        "    condition = (data['type'] == 9) & (data['cool_area'] < 500)\n",
        "    data.loc[condition, 'cool_area'] = round(data.loc[condition, 'all_area'] / result, 1)\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "Jqt9ToGApHOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_and_test_data(mode): # 훈련 데이터와 테스트 데이터를 불러오고, 전처리 과정을 수행한 뒤 반환하는 함수\n",
        "    # 데이터 로딩 및 전처리 과정 수행\n",
        "    building_info = pd.read_csv(os.path.join(base_path,'building_info.csv')).drop(['ESS저장용량(kWh)', 'PCS용량(kW)'], axis=1)\n",
        "    building_info = process_info(building_info)\n",
        "\n",
        "    train_data = pd.read_csv(os.path.join(base_path,'train.csv')).drop(['일조(hr)', '일사(MJ/m2)'], axis=1)\n",
        "    train_data.columns = ['num_date_time', 'building', 'date_time', 'temp', 'prec', 'wind', 'hum', 'target']\n",
        "    train_data = process_data(train_data, mode)\n",
        "\n",
        "    test_data = pd.read_csv(os.path.join(base_path,'test.csv'))\n",
        "    test_data.columns = ['num_date_time', 'building', 'date_time', 'temp', 'prec', 'wind', 'hum']\n",
        "    test_data = process_data(test_data, mode)\n",
        "\n",
        "    train_data, test_data = mean_std(train_data, test_data, mode)\n",
        "\n",
        "    if mode == 'all' or mode == 'gu_all':\n",
        "        train_data = train_data.merge(building_info, on='building', how='left')\n",
        "        test_data = test_data.merge(building_info, on='building', how='left')\n",
        "\n",
        "    return train_data, test_data"
      ],
      "metadata": {
        "id": "n7bblJ_lpW0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summer_cos(date): # 주어진 날짜의 코사인 값을 계산하여 여름철의 주기성을 반영\n",
        "    start_date = datetime.strptime(\"2022-06-01\", \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(\"2022-09-14\", \"%Y-%m-%d\")\n",
        "\n",
        "    period = (end_date - start_date).total_seconds()\n",
        "\n",
        "    return math.cos(2 * math.pi * (date - start_date).total_seconds() / period)\n",
        "\n",
        "def summer_sin(date): # 주어진 날짜의 사인 값을 계산하여 여름철의 주기성을 반영\n",
        "    start_date = datetime.strptime(\"2022-06-01\", \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(\"2022-09-14\", \"%Y-%m-%d\")\n",
        "\n",
        "    period = (end_date - start_date).total_seconds()\n",
        "\n",
        "    return math.sin(2 * math.pi * (date - start_date).total_seconds() / period)"
      ],
      "metadata": {
        "id": "JMh5txkunAnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-01T03:37:35.490986Z",
          "iopub.status.busy": "2023-09-01T03:37:35.490745Z",
          "iopub.status.idle": "2023-09-01T03:46:08.864791Z",
          "shell.execute_reply": "2023-09-01T03:46:08.863796Z",
          "shell.execute_reply.started": "2023-09-01T03:37:35.490966Z"
        },
        "trusted": true,
        "id": "iojzdXYRGRdU",
        "outputId": "510fe58b-2be4-4d06-acd8-e0f46a9dcf74"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [03:01<00:00,  1.81s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.404954637397799\n",
            "451.67\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [05:16<00:00,  3.17s/it]\n"
          ]
        }
      ],
      "source": [
        "gu_byb = ['num_date_time', 'building', 'date_time', 'temp', 'wind', 'hum',\n",
        "       'dow', 'month', 'week', 'dow_hour_mean', 'holiday',\n",
        "       'holiday_mean', 'holiday_std', 'hour_mean', 'hour_std', 'sin_time',\n",
        "       'cos_time', 'THI', 'WC', 'CDH', 'target']\n",
        "\n",
        "train, test = get_train_and_test_data('gu_byb')\n",
        "\n",
        "train = train[gu_byb]\n",
        "test = test[gu_byb[:-1]]\n",
        "\n",
        "scores = []\n",
        "best_it = []\n",
        "\n",
        "score = pd.DataFrame({'building':range(1,101)})\n",
        "for i in tqdm(range(100)):\n",
        "    y = train.loc[train.building == i+1, 'target']\n",
        "    x = train.loc[train.building == i+1, ].iloc[:, 3:].drop(['target'], axis=1)\n",
        "    y_train, y_valid, x_train, x_valid = temporal_train_test_split(y = y, X = x, test_size = 168)\n",
        "\n",
        "    xgb = XGBRegressor(colsample_bytree=0.8, eta=0.01, max_depth=5,\n",
        "             min_child_weight=6,n_estimators=2000, subsample=0.9, early_stopping_rounds=50, eval_metric=SMAPE)\n",
        "\n",
        "    xgb.set_params(**{'objective':weighted_mse(100)})\n",
        "\n",
        "    xgb.fit(x_train, y_train, eval_set=[(x_train, y_train),\n",
        "                                            (x_valid, y_valid)], verbose=False)\n",
        "\n",
        "    y_pred = xgb.predict(x_valid)\n",
        "\n",
        "    sm = SMAPE(y_valid, y_pred)\n",
        "    scores.append(sm)\n",
        "    best_it.append(xgb.best_iteration+1)\n",
        "\n",
        "score['score'] = scores\n",
        "print(sum(scores)/len(scores))\n",
        "print(sum(best_it)/len(best_it))\n",
        "# 4.404954637397799\n",
        "# 451.67\n",
        "\n",
        "preds = np.array([])\n",
        "\n",
        "for i in tqdm(range(100)):\n",
        "    pred_df = pd.DataFrame()\n",
        "\n",
        "    for seed in [0,1,2,3,4]:\n",
        "        y_train = train.loc[train.building == i+1, 'target']\n",
        "        x_train = train.loc[train.building == i+1, ].iloc[:, 3:].drop(['target'], axis=1)\n",
        "        x_test = test.loc[test.building == i+1, ].iloc[:,3:]\n",
        "\n",
        "        xgb = XGBRegressor(colsample_bytree=0.8, eta=0.01, max_depth=5, seed=seed,\n",
        "                 min_child_weight=6,n_estimators=best_it[i], subsample=0.9)\n",
        "\n",
        "        xgb.fit(x_train, y_train)\n",
        "        y_pred = xgb.predict(x_test)\n",
        "        pred_df.loc[:,seed] = y_pred\n",
        "\n",
        "    pred = pred_df.mean(axis=1)\n",
        "    preds = np.append(preds, pred)\n",
        "\n",
        "submission = pd.read_csv(os.path.join(base_path,'sample_submission.csv'))\n",
        "submission['answer'] = preds\n",
        "submission.to_csv('./gu_byb.csv', index = False)\n",
        "\n",
        "del train, test, scores, best_it, submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-01T03:46:08.867514Z",
          "iopub.status.busy": "2023-09-01T03:46:08.867161Z",
          "iopub.status.idle": "2023-09-01T03:46:24.068528Z",
          "shell.execute_reply": "2023-09-01T03:46:24.067167Z",
          "shell.execute_reply.started": "2023-09-01T03:46:08.867492Z"
        },
        "trusted": true,
        "id": "ARvMFoD9GRdV"
      },
      "outputs": [],
      "source": [
        "train, test = get_train_and_test_data('gu_all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-01T03:46:24.070129Z",
          "iopub.status.busy": "2023-09-01T03:46:24.069862Z",
          "iopub.status.idle": "2023-09-01T03:46:24.076334Z",
          "shell.execute_reply": "2023-09-01T03:46:24.074972Z",
          "shell.execute_reply.started": "2023-09-01T03:46:24.070106Z"
        },
        "trusted": true,
        "id": "e10c2FsvGRdV"
      },
      "outputs": [],
      "source": [
        "# 10시간 정도 소요됩니다.\n",
        "\n",
        "# import optuna\n",
        "# import optuna.logging\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "# train['date'] = pd.to_datetime(train['date'])\n",
        "# train['building'] = train['building'].astype('category')\n",
        "# train['type'] = train['type'].astype('category')\n",
        "\n",
        "# x_train = train[train['date'] < '2022-08-18'].drop(['num_date_time', 'date_time', 'target', 'date'], axis=1)\n",
        "# x_valid = train[train['date'] >= '2022-08-18'].drop(['num_date_time', 'date_time', 'target', 'date'], axis=1)\n",
        "# y_train = train[train['date'] < '2022-08-18']['target']\n",
        "# y_valid = train[train['date'] >= '2022-08-18']['target']\n",
        "\n",
        "# dtrain = xgb.DMatrix(data=x_train, label=y_train, enable_categorical=True)\n",
        "# dvalid = xgb.DMatrix(data=x_valid, label=y_valid, enable_categorical=True)\n",
        "\n",
        "# def objective(trial):\n",
        "#     param = {\n",
        "#         'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0),\n",
        "#         'gamma': trial.suggest_float('gamma', 1e-3, 10),\n",
        "#         'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0),\n",
        "#         'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n",
        "#         'subsample': trial.suggest_categorical('subsample', [0.6, 0.7, 0.8, 1.0]),\n",
        "#         'max_depth': trial.suggest_categorical('max_depth', [3, 4, 5, 6]),\n",
        "#         'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
        "#         'eta' : 0.1\n",
        "#     }\n",
        "\n",
        "#     model = xgb.train(params=param, dtrain=dtrain, num_boost_round=1000,\n",
        "#                       evals=[(dvalid, 'valid')], early_stopping_rounds=50, verbose_eval=False)\n",
        "\n",
        "#     preds = model.predict(dvalid)\n",
        "#     smape = SMAPE(y_valid, preds)\n",
        "\n",
        "#     return smape\n",
        "\n",
        "# study = optuna.create_study(direction='minimize', study_name=None)\n",
        "# with tqdm(total=500) as pbar:\n",
        "#     def callback(study, trial):\n",
        "#         pbar.update(1)\n",
        "\n",
        "#     study.optimize(objective, n_trials=500, callbacks=[callback])\n",
        "\n",
        "# df = study.trials_dataframe().sort_values(by=['value'], ascending=[True]).reset_index(drop=True)\n",
        "# df.to_csv('parameters.csv', index=False)\n",
        "# df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-01T03:46:24.078633Z",
          "iopub.status.busy": "2023-09-01T03:46:24.078279Z",
          "iopub.status.idle": "2023-09-01T03:46:24.094083Z",
          "shell.execute_reply": "2023-09-01T03:46:24.093080Z",
          "shell.execute_reply.started": "2023-09-01T03:46:24.078602Z"
        },
        "trusted": true,
        "id": "TkMyxvVsGRdV"
      },
      "outputs": [],
      "source": [
        "colsample_bytree = [0.9,0.9,0.8,0.9,0.9]\n",
        "gamma = [8.161415, 8.915918, 8.249356, 6.575258, 8.487247]\n",
        "max_depth = [6,5,6,6,6]\n",
        "min_child_weight = [47,8,30,54,77]\n",
        "reg_alpha = [6.721675, 6.736361, 7.109872, 7.016596, 6.186162]\n",
        "reg_lambda = [6.064121, 5.957454, 5.927528, 5.413840, 4.798086]\n",
        "subsample = [1.0,1.0,1.0,1.0,1.0]\n",
        "value = [5.010795, 5.016419, 5.017388, 5.023210, 5.028135]\n",
        "\n",
        "df = pd.DataFrame({'params_colsample_bytree':colsample_bytree, 'params_gamma':gamma, 'params_max_depth':max_depth, 'params_min_child_weight':min_child_weight,\n",
        "             'params_reg_alpha':reg_alpha, 'params_reg_lambda':reg_lambda, 'params_subsample':subsample, 'value':value})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-01T03:46:24.095727Z",
          "iopub.status.busy": "2023-09-01T03:46:24.095426Z",
          "iopub.status.idle": "2023-09-01T03:46:57.397931Z",
          "shell.execute_reply": "2023-09-01T03:46:57.396514Z",
          "shell.execute_reply.started": "2023-09-01T03:46:24.095703Z"
        },
        "trusted": true,
        "id": "j31nRK8gGRdV",
        "outputId": "0670e901-1818-4a1e-e632-35390fd1e815"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.010795060857856 251\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "gu_all = ['num_date_time', 'building', 'date_time', 'temp', 'wind', 'hum',\n",
        "       'type', 'all_area', 'cool_area', 'dow', 'month', 'week',\n",
        "       'dow_hour_mean', 'date', 'holiday', 'holiday_mean', 'holiday_std',\n",
        "       'hour_mean', 'hour_std', 'sin_time', 'cos_time', 'THI', 'WC', 'CDH', 'target']\n",
        "\n",
        "train, test = train[gu_all], test[gu_all[:-1]]\n",
        "\n",
        "train['date'] = pd.to_datetime(train['date'])\n",
        "train['building'] = train['building'].astype('category')\n",
        "train['type'] = train['type'].astype('category')\n",
        "\n",
        "x_train = train[train['date'] < f'2022-08-18'].drop(['num_date_time', 'date_time', 'target', 'date'], axis=1).reset_index(drop=True)\n",
        "x_valid = train[train['date'] >= f'2022-08-18'].drop(['num_date_time', 'date_time', 'target', 'date'], axis=1).reset_index(drop=True)\n",
        "y_train = train[train['date'] < f'2022-08-18']['target'].reset_index(drop=True)\n",
        "y_valid = train[train['date'] >= f'2022-08-18']['target'].reset_index(drop=True)\n",
        "\n",
        "dtrain = xgb.DMatrix(data=x_train, label=y_train, enable_categorical=True)\n",
        "dvalid = xgb.DMatrix(data=x_valid, label=y_valid, enable_categorical=True)\n",
        "\n",
        "\n",
        "param = {\n",
        "    'reg_lambda': df['params_reg_lambda'][0] ,\n",
        "    'gamma': df['params_gamma'][0],\n",
        "    'reg_alpha': df['params_reg_alpha'][0] ,\n",
        "    'colsample_bytree': df['params_colsample_bytree'][0] ,\n",
        "    'subsample': df['params_subsample'][0] ,\n",
        "    'max_depth': df['params_max_depth'][0],\n",
        "    'min_child_weight': df['params_min_child_weight'][0],\n",
        "}\n",
        "\n",
        "model = xgb.train(params=param, dtrain=dtrain, num_boost_round=1000,\n",
        "                  evals=[(dvalid, 'valid')], early_stopping_rounds=100, verbose_eval=False)\n",
        "\n",
        "preds = model.predict(dvalid)\n",
        "smape = SMAPE(y_valid, preds)\n",
        "\n",
        "best_it = model.best_iteration+1\n",
        "building_score = []\n",
        "for i in range(100):\n",
        "    building_score.append(SMAPE(y_valid[i*168:(i+1)*168], preds[i*168:(i+1)*168]))\n",
        "\n",
        "score['score_all'] = building_score\n",
        "score.to_csv('./score.csv', index=False)\n",
        "print(smape, best_it)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-01T03:46:57.399448Z",
          "iopub.status.busy": "2023-09-01T03:46:57.399106Z",
          "iopub.status.idle": "2023-09-01T03:49:03.524307Z",
          "shell.execute_reply": "2023-09-01T03:49:03.523477Z",
          "shell.execute_reply.started": "2023-09-01T03:46:57.399423Z"
        },
        "trusted": true,
        "id": "dO0me2PHGRdV",
        "outputId": "bd4592c2-0720-473f-a627-3a4ece1068dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [02:05<00:00, 25.19s/it]\n"
          ]
        }
      ],
      "source": [
        "preds = np.array([])\n",
        "\n",
        "test = test.copy()\n",
        "test['date'] = pd.to_datetime(test['date'])\n",
        "test['building'] = test['building'].astype('category')\n",
        "test['type'] = test['type'].astype('category')\n",
        "\n",
        "x_train = train.drop(['num_date_time', 'date_time', 'target', 'date'], axis=1)\n",
        "x_test = test.drop(['num_date_time', 'date_time', 'date'], axis=1)\n",
        "y_train = train['target']\n",
        "\n",
        "dtrain = xgb.DMatrix(data=x_train, label=y_train, enable_categorical=True)\n",
        "dtest = xgb.DMatrix(data=x_test, enable_categorical=True)\n",
        "\n",
        "pred_df = pd.DataFrame()\n",
        "\n",
        "for seed in tqdm(range(5)):\n",
        "    param = {\n",
        "        'reg_lambda': df['params_reg_lambda'][0] ,\n",
        "        'gamma': df['params_gamma'][0],\n",
        "        'reg_alpha': df['params_reg_alpha'][0] ,\n",
        "        'colsample_bytree': df['params_colsample_bytree'][0] ,\n",
        "        'subsample': df['params_subsample'][0] ,\n",
        "        'max_depth': df['params_max_depth'][0],\n",
        "        'min_child_weight': df['params_min_child_weight'][0],\n",
        "        'seed':seed,\n",
        "    }\n",
        "\n",
        "    model = xgb.train(params=param, dtrain=dtrain, num_boost_round=best_it)\n",
        "\n",
        "    y_pred = model.predict(dtest)\n",
        "    pred_df.loc[:,seed] = y_pred\n",
        "\n",
        "pred = pred_df.mean(axis=1)\n",
        "preds = np.append(preds, pred)\n",
        "\n",
        "submission = pd.read_csv(os.path.join(base_path,'sample_submission.csv'))\n",
        "submission['answer'] = preds\n",
        "submission.to_csv('./gu_all.csv', index = False)\n",
        "\n",
        "del train, test, df, submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-01T03:49:03.526125Z",
          "iopub.status.busy": "2023-09-01T03:49:03.525616Z",
          "iopub.status.idle": "2023-09-01T03:49:48.432375Z",
          "shell.execute_reply": "2023-09-01T03:49:48.431440Z",
          "shell.execute_reply.started": "2023-09-01T03:49:03.526096Z"
        },
        "trusted": true,
        "id": "F50Txuo3GRdW",
        "outputId": "dec8422a-5575-4741-c519-62bec5c5fc3e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:26<00:00,  3.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.17304185151095\n",
            "107.93\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "byb = ['num_date_time', 'building', 'date_time', 'temp', 'wind', 'hum',\n",
        "       'dow', 'month', 'week', 'dow_hour_mean', 'holiday',\n",
        "       'holiday_mean', 'holiday_std', 'hour_mean', 'hour_std', 'sin_time',\n",
        "       'cos_time', 'THI', 'WC', 'CDH', 'summer_cos', 'summer_sin', 'target']\n",
        "\n",
        "train, test = get_train_and_test_data('byb')\n",
        "train, test = train[byb], test[byb[:-1]]\n",
        "\n",
        "scores = []\n",
        "best_it = []\n",
        "\n",
        "for b in tqdm(range(100)):\n",
        "    y = train.loc[train.building == b+1, 'target']\n",
        "    x = train.loc[train.building == b+1, ].iloc[:, 3:].drop(['target'], axis=1)\n",
        "    y_train, y_valid, x_train, x_valid = temporal_train_test_split(y = y, X = x, test_size = 168)\n",
        "\n",
        "    xgb = XGBRegressor(colsample_bytree=0.8, eta=0.1, max_depth=5,\n",
        "         min_child_weight=6,n_estimators=1000, subsample=0.9, early_stopping_rounds=50)\n",
        "\n",
        "    xgb.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], verbose=False)\n",
        "\n",
        "    y_pred = xgb.predict(x_valid)\n",
        "\n",
        "\n",
        "    sm = SMAPE(y_valid, y_pred)\n",
        "    scores.append(sm)\n",
        "    best_it.append(xgb.best_iteration+1)\n",
        "\n",
        "print(sum(scores)/len(scores))\n",
        "print(sum(best_it)/len(best_it))\n",
        "# 5.17304185151095\n",
        "# 107.93"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-01T03:49:48.435684Z",
          "iopub.status.busy": "2023-09-01T03:49:48.435399Z",
          "iopub.status.idle": "2023-09-01T03:52:58.734904Z",
          "shell.execute_reply": "2023-09-01T03:52:58.733287Z",
          "shell.execute_reply.started": "2023-09-01T03:49:48.435662Z"
        },
        "trusted": true,
        "id": "73hLRodMGRdW",
        "outputId": "6910c95f-172c-48e1-b6af-b8f3e0b01820"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [03:10<00:00,  1.90s/it]\n"
          ]
        }
      ],
      "source": [
        "preds = np.array([])\n",
        "\n",
        "for i in tqdm(range(100)):\n",
        "    pred_df = pd.DataFrame()\n",
        "\n",
        "    for seed in [0,1,2,3,4,5,6,7,8,9,10]:\n",
        "        y_train = train.loc[train.building == i+1, 'target']\n",
        "        x_train = train.loc[train.building == i+1, ].iloc[:, 3:].drop(['target'], axis=1)\n",
        "        x_test = test.loc[test.building == i+1, ].iloc[:,3:]\n",
        "\n",
        "        xgb = XGBRegressor(colsample_bytree=0.8, eta=0.1, max_depth=5, seed=seed,\n",
        "             min_child_weight=6,n_estimators=best_it[i], subsample=0.9)\n",
        "\n",
        "        xgb.fit(x_train, y_train)\n",
        "        y_pred = xgb.predict(x_test)\n",
        "        pred_df.loc[:,seed] = y_pred\n",
        "\n",
        "    pred = pred_df.mean(axis=1)\n",
        "    preds = np.append(preds, pred)\n",
        "\n",
        "submission = pd.read_csv(os.path.join(base_path,'sample_submission.csv'))\n",
        "submission['answer'] = preds\n",
        "submission.to_csv('./byb.csv', index = False)\n",
        "submission\n",
        "\n",
        "del train, test, scores, best_it, submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-01T03:52:58.736916Z",
          "iopub.status.busy": "2023-09-01T03:52:58.736570Z",
          "iopub.status.idle": "2023-09-01T03:52:58.743105Z",
          "shell.execute_reply": "2023-09-01T03:52:58.741776Z",
          "shell.execute_reply.started": "2023-09-01T03:52:58.736890Z"
        },
        "trusted": true,
        "id": "AEtWm38SGRdW"
      },
      "outputs": [],
      "source": [
        "# 10시간 정도 소요됩니다.\n",
        "\n",
        "# import optuna\n",
        "# import optuna.logging\n",
        "\n",
        "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "# train['date'] = pd.to_datetime(train['date'])\n",
        "# train['building'] = train['building'].astype('category')\n",
        "# train['type'] = train['type'].astype('category')\n",
        "\n",
        "# x_train = train[train['date'] < '2022-08-18'].drop(['num_date_time', 'date_time', 'target', 'date'], axis=1)\n",
        "# x_valid = train[train['date'] >= '2022-08-18'].drop(['num_date_time', 'date_time', 'target', 'date'], axis=1)\n",
        "# y_train = train[train['date'] < '2022-08-18']['target']\n",
        "# y_valid = train[train['date'] >= '2022-08-18']['target']\n",
        "\n",
        "# dtrain = xgb.DMatrix(data=x_train, label=y_train, enable_categorical=True)\n",
        "# dvalid = xgb.DMatrix(data=x_valid, label=y_valid, enable_categorical=True)\n",
        "\n",
        "# def objective(trial):\n",
        "#     param = {\n",
        "#         'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0),\n",
        "#         'gamma': trial.suggest_float('gamma', 1e-3, 10),\n",
        "#         'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0),\n",
        "#         'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n",
        "#         'subsample': trial.suggest_categorical('subsample', [0.6, 0.7, 0.8, 1.0]),\n",
        "#         'max_depth': trial.suggest_categorical('max_depth', [3, 4, 5, 6]),\n",
        "#         'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
        "#         'eta' : 0.1\n",
        "#     }\n",
        "\n",
        "#     model = xgb.train(params=param, dtrain=dtrain, num_boost_round=1000,\n",
        "#                       evals=[(dvalid, 'valid')], early_stopping_rounds=50, verbose_eval=False)\n",
        "\n",
        "#     preds = model.predict(dvalid)\n",
        "#     smape = SMAPE(y_valid, preds)\n",
        "\n",
        "#     return smape\n",
        "\n",
        "# study = optuna.create_study(direction='minimize', study_name=None)\n",
        "# with tqdm(total=500) as pbar:\n",
        "#     def callback(study, trial):\n",
        "#         pbar.update(1)\n",
        "\n",
        "#     study.optimize(objective, n_trials=500, callbacks=[callback])\n",
        "\n",
        "# df = study.trials_dataframe().sort_values(by=['value'], ascending=[True]).reset_index(drop=True)\n",
        "# df.to_csv('parameters2.csv', index=False)\n",
        "# df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-01T03:52:58.744657Z",
          "iopub.status.busy": "2023-09-01T03:52:58.744341Z",
          "iopub.status.idle": "2023-09-01T03:52:58.767006Z",
          "shell.execute_reply": "2023-09-01T03:52:58.765637Z",
          "shell.execute_reply.started": "2023-09-01T03:52:58.744628Z"
        },
        "trusted": true,
        "id": "2oIp0-ArGRdW"
      },
      "outputs": [],
      "source": [
        "data = [\n",
        "    [61, 61, 4.946742, '2023-08-18 11:59:30.066695', '2023-08-18 12:01:19.655572', '0 days 00:01:49.588877', 0.7, 0.695975, 6, 43, 6.357773, 2.568356, 1.0, 'COMPLETE'],\n",
        "    [23, 23, 4.950789, '2023-08-18 11:24:36.282096', '2023-08-18 11:25:56.779154', '0 days 00:01:20.497058', 0.7, 0.023800, 6, 30, 6.278440, 1.460707, 1.0, 'COMPLETE'],\n",
        "    [14, 14, 4.975757, '2023-08-18 11:16:59.783126', '2023-08-18 11:18:02.962945', '0 days 00:01:03.179819', 0.7, 0.966742, 6, 36, 3.762862, 0.362957, 1.0, 'COMPLETE'],\n",
        "    [51, 51, 4.986851, '2023-08-18 11:51:40.355474', '2023-08-18 11:52:48.657127', '0 days 00:01:08.301653', 0.7, 1.034617, 6, 49, 5.606792, 1.690612, 1.0, 'COMPLETE'],\n",
        "    [31, 31, 4.994619, '2023-08-18 11:32:34.984062', '2023-08-18 11:33:29.901314', '0 days 00:00:54.917252', 0.7, 0.094354, 6, 36, 5.006265, 1.527805, 1.0, 'COMPLETE'],\n",
        "    [71, 71, 5.450572, '2023-08-14 13:17:40.337706', '2023-08-14 13:20:33.336589', '0 days 00:02:52.998883', 1.0, 4.632731, 6, 18, 2.979220, 7.641126, 0.7, 'COMPLETE'],\n",
        "    [11, 11, 5.451309, '2023-08-14 11:00:11.878935', '2023-08-14 11:02:55.559494', '0 days 00:02:43.680559', 0.9, 8.375491, 6, 1, 4.829945, 7.857255, 0.7, 'COMPLETE'],\n",
        "    [32, 32, 5.451501, '2023-08-14 11:48:49.899305', '2023-08-14 11:51:31.199312', '0 days 00:02:41.300007', 0.9, 4.436363, 6, 1, 3.906413, 6.982815, 0.7, 'COMPLETE'],\n",
        "    [21, 21, 5.451785, '2023-08-14 11:22:30.440656', '2023-08-14 11:25:13.331292', '0 days 00:02:42.890636', 0.9, 3.917213, 6, 3, 4.037673, 8.432115, 0.7, 'COMPLETE'],\n",
        "    [89, 89, 5.451788, '2023-08-14 14:07:31.956578', '2023-08-14 14:10:27.640167', '0 days 00:02:55.683589', 1.0, 4.768440, 6, 9, 3.470846, 8.564962, 0.7, 'COMPLETE']\n",
        "]\n",
        "\n",
        "columns = ['number', 'number', 'value', 'datetime_start', 'datetime_complete', 'duration', 'params_colsample_bytree', 'params_gamma', 'params_max_depth', 'params_min_child_weight', 'params_reg_alpha', 'params_reg_lambda', 'params_subsample', 'state']\n",
        "\n",
        "df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "df['datetime_start'] = pd.to_datetime(df['datetime_start'])\n",
        "df['datetime_complete'] = pd.to_datetime(df['datetime_complete'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-01T04:04:34.593753Z",
          "iopub.status.busy": "2023-09-01T04:04:34.593412Z",
          "iopub.status.idle": "2023-09-01T04:04:34.607894Z",
          "shell.execute_reply": "2023-09-01T04:04:34.606698Z",
          "shell.execute_reply.started": "2023-09-01T04:04:34.593730Z"
        },
        "trusted": true,
        "id": "yg0nicXaGRdW"
      },
      "outputs": [],
      "source": [
        "def ratio_2(ratio):\n",
        "    score = pd.read_csv('./score.csv')\n",
        "    gu_byb = pd.read_csv('./gu_byb.csv')\n",
        "\n",
        "    ratio = np.array(ratio)\n",
        "\n",
        "    category_mappings = {\n",
        "        'one': ([32, 33, 34, 35, 36], [0.997, 0.999, 0.996, 0.997, 0.995, 0.994, 0.996], [], True),\n",
        "        'one_': ([56, 58], [0.997, 0.999, 0.998, 0.999, 0.995, 0.994, 0.996], [], True),\n",
        "        'two': ([24, 25, 26, 27, 48, 49, 50], [0.987, 0.987, 0.985, 0.987, 0.984, 0.982, 0.985], [], True),\n",
        "        'two_': ([23, 55], [0.987, 0.987, 0.995, 0.998, 0.984, 0.982, 0.985], [], True),\n",
        "        'depart': ([37, 38, 39, 40, 41, 42, 43, 44, 85], [0.998]*7, [], False),\n",
        "        'mart': ([86, 87, 88, 89, 90, 91, 92], [0.998]*7, [4], False),\n",
        "        'aprt': ([64, 65, 66, 67, 68, 61, 62, 63], [0.985, 0.985, 0.985, 0.987, 0.98, 0.98, 0.987], [], True),\n",
        "        'mon': ([2, 3, 54], [0.998]*7, [4], False),\n",
        "        '5': ([5], [0.998]*7, [0,4,5,6], False),\n",
        "        '8': ([8], [0.998]*7, [3], False)\n",
        "    }\n",
        "\n",
        "    for i in range(100):\n",
        "        rest =  True\n",
        "        for category, (ids, ratios, d, a_a) in category_mappings.items():\n",
        "            if i + 1 in ids:\n",
        "                rest = False\n",
        "                for j in range(7):\n",
        "                    if j in d:\n",
        "                        continue\n",
        "                    ran,ge = 168*i+24*j,168*i+24*(j+1)\n",
        "                    if a_a:\n",
        "                        if category == 'aprt':\n",
        "                            ratio[ran:ge] *= ratios[j]\n",
        "                        else:\n",
        "                            ratio[ran:ge] = gu_byb.answer[ran:ge]*ratios[j]\n",
        "                    else:\n",
        "                        ratio[ran+9:ge-3] *= ratios[j]\n",
        "                break\n",
        "        if rest:\n",
        "            for j in range(7):\n",
        "                ran,ge = 168*i+24*j,168*i+24*(j+1)\n",
        "                if j in [2, 3]:\n",
        "                    continue\n",
        "                ratio[ran+9:ge-3] *= ratios[j]\n",
        "\n",
        "    return ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-01T03:52:58.782124Z",
          "iopub.status.busy": "2023-09-01T03:52:58.781844Z",
          "iopub.status.idle": "2023-09-01T03:54:41.848475Z",
          "shell.execute_reply": "2023-09-01T03:54:41.847837Z",
          "shell.execute_reply.started": "2023-09-01T03:52:58.782102Z"
        },
        "trusted": true,
        "id": "IcNhNofUGRdW",
        "outputId": "db55add7-16ce-4a5b-9726-5f8d0d7d0c64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.946742493265771 844\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "_all = ['num_date_time', 'building', 'date_time', 'temp', 'prec', 'wind', 'hum',\n",
        "       'type', 'all_area', 'cool_area', 'sun', 'dow', 'month',\n",
        "       'week', 'avg_temp', 'max_temp', 'min_temp', 'temp_diff',\n",
        "       'dow_hour_mean', 'holiday', 'holiday_mean', 'holiday_std',\n",
        "       'hour_mean', 'hour_std', 'sin_time', 'cos_time', 'THI', 'WC', 'CDH', 'target']\n",
        "\n",
        "train, test = get_train_and_test_data('all')\n",
        "train, test = train[_all], test[_all[:-1]]\n",
        "\n",
        "train['date'] = pd.to_datetime(train['date_time'])\n",
        "train['building'] = train['building'].astype('category')\n",
        "train['type'] = train['type'].astype('category')\n",
        "\n",
        "x_train = train[train['date'] < '2022-08-18'].drop(['num_date_time', 'date_time', 'target', 'date'], axis=1)\n",
        "x_valid = train[train['date'] >= '2022-08-18'].drop(['num_date_time', 'date_time', 'target', 'date'], axis=1)\n",
        "y_train = train[train['date'] < '2022-08-18']['target']\n",
        "y_valid = train[train['date'] >= '2022-08-18']['target']\n",
        "\n",
        "dtrain = xgb.DMatrix(data=x_train, label=y_train, enable_categorical=True)\n",
        "dvalid = xgb.DMatrix(data=x_valid, label=y_valid, enable_categorical=True)\n",
        "\n",
        "param = {\n",
        "    'reg_lambda': df['params_reg_lambda'][0] ,\n",
        "    'gamma': df['params_gamma'][0],\n",
        "    'reg_alpha': df['params_reg_alpha'][0] ,\n",
        "    'colsample_bytree': df['params_colsample_bytree'][0] ,\n",
        "    'subsample': df['params_subsample'][0] ,\n",
        "    'max_depth': df['params_max_depth'][0],\n",
        "    'min_child_weight': df['params_min_child_weight'][0],\n",
        "    'eta' : 0.1,\n",
        "}\n",
        "\n",
        "\n",
        "model = xgb.train(params=param, dtrain=dtrain, num_boost_round=1000,\n",
        "                  evals=[(dvalid, 'valid')], early_stopping_rounds=50, verbose_eval=False)\n",
        "\n",
        "preds = model.predict(dvalid)\n",
        "\n",
        "smape = SMAPE(y_valid, preds)\n",
        "\n",
        "score = smape\n",
        "best_it = model.best_iteration+1\n",
        "print(score, best_it) # 4.946742493265771 [844]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-01T03:54:41.850685Z",
          "iopub.status.busy": "2023-09-01T03:54:41.850330Z",
          "iopub.status.idle": "2023-09-01T04:01:22.615043Z",
          "shell.execute_reply": "2023-09-01T04:01:22.614053Z",
          "shell.execute_reply.started": "2023-09-01T03:54:41.850659Z"
        },
        "trusted": true,
        "id": "GhrhX_6ZGRdW",
        "outputId": "52de1213-a473-46ec-9b33-bf62aab33204"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [06:40<00:00, 80.12s/it]\n"
          ]
        }
      ],
      "source": [
        "preds = np.array([])\n",
        "\n",
        "test['date'] = pd.to_datetime(test['date_time'])\n",
        "test['building'] = test['building'].astype('category')\n",
        "test['type'] = test['type'].astype('category')\n",
        "\n",
        "x_train = train.drop(['num_date_time', 'date_time', 'target', 'date'], axis=1)\n",
        "x_test = test.drop(['num_date_time', 'date_time', 'date'], axis=1)\n",
        "y_train = train['target']\n",
        "\n",
        "dtrain = xgb.DMatrix(data=x_train, label=y_train, enable_categorical=True)\n",
        "dtest = xgb.DMatrix(data=x_test, enable_categorical=True)\n",
        "\n",
        "pred_df = pd.DataFrame()\n",
        "\n",
        "i = 0\n",
        "for seed in tqdm(range(5)):\n",
        "    param = {\n",
        "        'reg_lambda': df['params_reg_lambda'][0] ,\n",
        "        'gamma': df['params_gamma'][0],\n",
        "        'reg_alpha': df['params_reg_alpha'][0] ,\n",
        "        'colsample_bytree': df['params_colsample_bytree'][0] ,\n",
        "        'subsample': df['params_subsample'][0] ,\n",
        "        'max_depth': df['params_max_depth'][0],\n",
        "        'min_child_weight': df['params_min_child_weight'][0],\n",
        "        'seed':seed,\n",
        "        'eta':0.1\n",
        "    }\n",
        "\n",
        "    model = xgb.train(params=param, dtrain=dtrain, num_boost_round=best_it-100)\n",
        "\n",
        "    y_pred = model.predict(dtest)\n",
        "    pred_df.loc[:,seed] = y_pred\n",
        "\n",
        "pred = pred_df.mean(axis=1)\n",
        "preds = np.append(preds, pred)\n",
        "\n",
        "submission = pd.read_csv(os.path.join(base_path,'sample_submission.csv'))\n",
        "submission['answer'] = preds\n",
        "submission.to_csv('./all.csv', index = False)\n",
        "\n",
        "del train, test\n",
        "del dtrain, dtest, x_train, x_test, y_train, pred, preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-01T04:04:41.070143Z",
          "iopub.status.busy": "2023-09-01T04:04:41.069067Z",
          "iopub.status.idle": "2023-09-01T04:04:41.426662Z",
          "shell.execute_reply": "2023-09-01T04:04:41.425705Z",
          "shell.execute_reply.started": "2023-09-01T04:04:41.070108Z"
        },
        "trusted": true,
        "id": "vftHWWGiGRdW",
        "outputId": "4cce49f5-28a0-471e-8e7e-4b821477209f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_date_time</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1_20220825 00</td>\n",
              "      <td>1802.679429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1_20220825 01</td>\n",
              "      <td>1753.577321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1_20220825 02</td>\n",
              "      <td>1636.800049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1_20220825 03</td>\n",
              "      <td>1567.376650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1_20220825 04</td>\n",
              "      <td>1611.254585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16795</th>\n",
              "      <td>100_20220831 19</td>\n",
              "      <td>857.328171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16796</th>\n",
              "      <td>100_20220831 20</td>\n",
              "      <td>799.987912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16797</th>\n",
              "      <td>100_20220831 21</td>\n",
              "      <td>718.364396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16798</th>\n",
              "      <td>100_20220831 22</td>\n",
              "      <td>617.148597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16799</th>\n",
              "      <td>100_20220831 23</td>\n",
              "      <td>526.372424</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16800 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         num_date_time       answer\n",
              "0        1_20220825 00  1802.679429\n",
              "1        1_20220825 01  1753.577321\n",
              "2        1_20220825 02  1636.800049\n",
              "3        1_20220825 03  1567.376650\n",
              "4        1_20220825 04  1611.254585\n",
              "...                ...          ...\n",
              "16795  100_20220831 19   857.328171\n",
              "16796  100_20220831 20   799.987912\n",
              "16797  100_20220831 21   718.364396\n",
              "16798  100_20220831 22   617.148597\n",
              "16799  100_20220831 23   526.372424\n",
              "\n",
              "[16800 rows x 2 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = pd.read_csv(os.path.join(base_path, 'test.csv'))\n",
        "test.columns = ['num_date_time', 'building', 'date_time', 'temp', 'prec', 'wind', 'hum']\n",
        "date = pd.to_datetime(test.date_time)\n",
        "test['dow'] = date.dt.weekday\n",
        "test['hour'] = date.dt.hour\n",
        "\n",
        "score = pd.read_csv('./score.csv')\n",
        "gu_byb = pd.read_csv('./gu_byb.csv')\n",
        "gu_all = pd.read_csv('./gu_all.csv')\n",
        "byb = pd.read_csv('./byb.csv')\n",
        "xg_all = pd.read_csv('./all.csv')\n",
        "\n",
        "ratio = []\n",
        "for i in range(100):\n",
        "    s1, s2 = score.score[i], score.score_all[i]\n",
        "    b1 = gu_all.answer[i * 168 : (i + 1) * 168] * (s1 / (s1 + s2))\n",
        "    b2 = gu_byb.answer[i * 168 : (i + 1) * 168] * (s2 / (s1 + s2)) * 0.965\n",
        "    building = [i + j for i, j in zip(b1, b2)]\n",
        "    ratio += building\n",
        "\n",
        "test['ratio'] = ((gu_all.answer + gu_byb.answer) * 0.5 * 0.98 + ratio) * 0.5\n",
        "test['gu_all'] = gu_all.answer\n",
        "\n",
        "ratio_values = [0.98, 0.975, 0.975, 0.99, 0.99, 0.985, 0.985]\n",
        "test['target'] = test['ratio'] * 0.5 + gu_all['answer'] * 0.5\n",
        "test['target'] = test.apply(lambda row: row['target'] * ratio_values[row['dow']], axis=1)\n",
        "\n",
        "ratio = ratio_2(np.array(test.target * 0.5 + (byb.answer * 0.5 + xg_all.answer * 0.5) * 0.5))\n",
        "\n",
        "submission = pd.read_csv(os.path.join(base_path, 'sample_submission.csv'))\n",
        "submission['answer'] = ratio\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWRHBe-lGRdW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}